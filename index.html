<!doctype html>
<html>
<head>
<title>Pooh Reactive Voice Element</title>
<style>body{margin:0;overflow:hidden;}</style>
</head>
<body>
<canvas id="canvas"></canvas>
<img id="source" src="data:image/png;base64,[INSERT_BASE64_OF_POOH_FACE_IMAGE_HERE]" style="display:none;" crossorigin="anonymous">
<button id="test" style="position:absolute;top:10px;left:10px;">Test Voice</button>
<script type="module">
import * as THREE from 'https://unpkg.com/three@latest/build/three.module.js';
import {EffectComposer} from 'https://unpkg.com/three@latest/examples/jsm/postprocessing/EffectComposer.js';
import {RenderPass} from 'https://unpkg.com/three@latest/examples/jsm/postprocessing/RenderPass.js';
import {UnrealBloomPass} from 'https://unpkg.com/three@latest/examples/jsm/postprocessing/UnrealBloomPass.js';

const ELEVEN_LABS_API_KEY = 'YOUR_ELEVEN_LABS_API_KEY_HERE';
const VOICE_ID = 'YOUR_POOH_VOICE_ID_HERE'; // Use Eleven Labs to create a Pooh-like voice

const canvas = document.getElementById('canvas');
const renderer = new THREE.WebGLRenderer({canvas});
renderer.setSize(window.innerWidth, window.innerHeight);

const scene = new THREE.Scene();
const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
camera.position.z = 50;

const composer = new EffectComposer(renderer);
const renderPass = new RenderPass(scene, camera);
composer.addPass(renderPass);
const bloomPass = new UnrealBloomPass(new THREE.Vector2(window.innerWidth, window.innerHeight), 1.5, 0.4, 0.85);
composer.addPass(bloomPass);

let particles, material;
const particleCount = 10000; // Adjust for performance

const img = document.getElementById('source');
img.onload = () => {
  const tempCanvas = document.createElement('canvas');
  tempCanvas.width = img.width;
  tempCanvas.height = img.height;
  const ctx = tempCanvas.getContext('2d');
  ctx.drawImage(img, 0, 0);
  const imageData = ctx.getImageData(0, 0, img.width, img.height);
  const data = imageData.data;

  const positions = [];
  const colors = [];
  const targets = [];
  const starts = [];

  for (let y = 0; y < img.height; y += 2) { // Sample every 2 pixels
    for (let x = 0; x < img.width; x += 2) {
      const i = (y * img.width + x) * 4;
      const r = data[i], g = data[i+1], b = data[i+2], a = data[i+3];
      if (a > 0 && !(r > 200 && g < 50 && b < 50)) { // Skip transparent or red background
        const px = (x - img.width / 2) / 2; // Scale
        const py = (img.height / 2 - y) / 2;
        targets.push(px, py, 0);
        colors.push(r/255, g/255, b/255);
        starts.push((Math.random() - 0.5) * 100, (Math.random() - 0.5) * 100, (Math.random() - 0.5) * 100);
        positions.push(starts[starts.length - 3], starts[starts.length - 2], starts[starts.length - 1]);
      }
    }
  }

  const geometry = new THREE.BufferGeometry();
  geometry.setAttribute('position', new THREE.Float32BufferAttribute(positions, 3));
  geometry.setAttribute('start', new THREE.Float32BufferAttribute(starts, 3));
  geometry.setAttribute('target', new THREE.Float32BufferAttribute(targets, 3));
  geometry.setAttribute('color', new THREE.Float32BufferAttribute(colors, 3));

  const vertexShader = `
    attribute vec3 start;
    attribute vec3 target;
    attribute vec3 color;
    varying vec3 vColor;
    uniform float morph;
    uniform float size;
    void main() {
      vColor = color;
      vec3 pos = mix(start, target, morph);
      gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);
      gl_PointSize = size;
    }
  `;

  const fragmentShader = `
    varying vec3 vColor;
    void main() {
      gl_FragColor = vec4(vColor, 1.0);
    }
  `;

  material = new THREE.ShaderMaterial({
    vertexShader,
    fragmentShader,
    uniforms: {
      morph: {value: 0},
      size: {value: 1.0}
    },
    vertexColors: true,
    blending: THREE.AdditiveBlending,
    depthTest: false,
    transparent: true
  });

  particles = new THREE.Points(geometry, material);
  scene.add(particles);
};

let morph = 0;
let targetMorph = 0;
let amplitude = 0;

function animate() {
  requestAnimationFrame(animate);
  morph += (targetMorph - morph) * 0.05;
  material.uniforms.morph.value = morph;
  material.uniforms.size.value = 1 + amplitude * 5;
  bloomPass.strength = 1.5 + amplitude * 2;
  composer.render();
}
animate();

window.addEventListener('resize', () => {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(window.innerWidth, window.innerHeight);
  composer.setSize(window.innerWidth, window.innerHeight);
});

// Voice Input
navigator.mediaDevices.getUserMedia({audio: true}).then(stream => {
  const audioContext = new AudioContext();
  const analyser = audioContext.createAnalyser();
  const microphone = audioContext.createMediaStreamSource(stream);
  microphone.connect(analyser);
  analyser.fftSize = 256;
  const bufferLength = analyser.frequencyBinCount;
  const dataArray = new Uint8Array(bufferLength);

  function updateAudio() {
    requestAnimationFrame(updateAudio);
    analyser.getByteFrequencyData(dataArray);
    amplitude = dataArray.reduce((a, b) => a + b) / (bufferLength * 255);
    targetMorph = amplitude > 0.1 ? 1 : 0; // Threshold for activation
  }
  updateAudio();
});

// Eleven Labs Integration Placeholder
async function speak(text) {
  const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}/stream`, {
    method: 'POST',
    headers: {
      'accept': 'audio/mpeg',
      'xi-api-key': ELEVEN_LABS_API_KEY,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({text, model_id: 'eleven_monolingual_v1'})
  });
  const audioBlob = await response.blob();
  const audioUrl = URL.createObjectURL(audioBlob);
  const audio = new Audio(audioUrl);
  audio.play();
}

document.getElementById('test').addEventListener('click', () => speak('Oh, bother! Hello from Pooh.'));

</script>
</body>
</html>